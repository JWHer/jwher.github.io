<!doctype html>
<html lang="kr" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.20">
<link rel="alternate" type="application/rss+xml" href="/posts/rss.xml" title="JWHer Tech Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/posts/atom.xml" title="JWHer Tech Blog Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","G-XHBVCY40VB","auto"),ga("set","anonymizeIp",!0),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><title data-rh="true">Alphapose 논문 리뷰와 사용 | JWHer Tech Blog</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://jwher.github.io/posts/alphapose"><meta data-rh="true" name="docusaurus_locale" content="kr"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="kr"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Alphapose 논문 리뷰와 사용 | JWHer Tech Blog"><meta data-rh="true" name="description" content="Alphapose 논문 리뷰와 사용"><meta data-rh="true" property="og:description" content="Alphapose 논문 리뷰와 사용"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2021-05-24T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/jwher"><meta data-rh="true" property="article:tag" content="paper,ml"><link data-rh="true" rel="icon" href="/img/logo.svg"><link data-rh="true" rel="canonical" href="https://jwher.github.io/posts/alphapose"><link data-rh="true" rel="alternate" href="https://jwher.github.io/en/posts/alphapose" hreflang="en"><link data-rh="true" rel="alternate" href="https://jwher.github.io/posts/alphapose" hreflang="kr"><link data-rh="true" rel="alternate" href="https://jwher.github.io/posts/alphapose" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.bcb72c7e.css">
<link rel="preload" href="/assets/js/runtime~main.0c1c803e.js" as="script">
<link rel="preload" href="/assets/js/main.9d471611.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Site Logo" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/logo.svg" alt="Site Logo" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title text--truncate">JWHer Tech Blog</b></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/posts">Posts</a><a class="navbar__item navbar__link" href="/categories">Categories</a><a href="https://github.com/jwher" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link icon-github"></a><a href="https://www.linkedin.com/in/jwher" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link icon-linkedin"></a><a href="https://www.instagram.com/jwher96" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link icon-instagram"></a><div class="toggle_S7eR colorModeToggle_vKtC"><button class="clean-btn toggleButton_rCf9 toggleButtonDisabled_Pu9x" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_v35p"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_nQuB"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_dLyj"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper"><div class="posts__header_mMDK"><div class="filter_lpre"></div><h2 class="presentation__title">Posts</h2><h6 class="presentation__subtitle">Let thine heart retain my words: Keep my commandments, and live.</h6></div><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_TMXw thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_V4zb margin-bottom--md">All posts</div><ul class="sidebarItemList_uHd5 clean-list"><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/concurrency-models-4">7가지 동시성 모델(스레드와 락) 거인의 어깨 위에서</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/concurrency-models-3">7가지 동시성 모델(스레드와 락) 고유 락 개선하기</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/concurrency-models-2">7가지 동시성 모델(스레드와 락) 상호 배제와 메모리 모델</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/concurrency-models-1">7가지 동시성 모델(소개)</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/requirement-levels">요구사항에 사용하는 RFC 키워드</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/hidden-technical-debt">머신러닝에 숨은 기술 부채</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/api-design-for-long-jobs">오래걸리는 API 설계</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/deep-learning-on-a-data-diet">학습에 중요한 데이터 찾기</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/ngrx">NGRX 반응형 웹을 위한 상태 관리</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/power-series">다양한 급수</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/build-opencv-with-java">Build OpenCV with Java</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/binomial-theorem">이항정리 - π값을 구하는 법</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/nvidia-gpu-architectures">Nvidia GPU 아키텍처</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/pytorch-in-m1">Pytorch in M1</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/agile">Agile</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/first-post-with-docusaurus">First post with docusaurus</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/ensemble-methods">Ensemble Methods</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/uncertainty-estimation">Uncertainty Estimation</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/Intelligent-Computer-Vision-1">Intelligent Computer Vision 1</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/kubernetes-architecture">쿠버네티스 아키텍처</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/kubeflow-guide">Kubeflow Guide</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/sagemaker">Sagemaker</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/blog-tech-map">Blog Tech Map</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/cncf">Cncf</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/envoy">Envoy</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/istio">Istio</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/dex">Dex</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/k8s-tip-configmap">K8S Tip Configmap</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/golang-setup">Golang Setup</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/docker-shared-volume">Docker Shared Volume</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/variable-autoencoder">Variable Autoencoder</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/k8s-tip-pv-terminating">K8S Tip Pv Terminating</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/free-wildcard-dns">Free Wildcard Dns</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/install-harbor">Install Harbor</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/install-helm">Install Helm</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/github-issue">Github Issue</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/k8s-tip-rollback">K8S Tip Rollback</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/k8s-tip-expose-service">K8S Tip Expose Service</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/uuid">Uuid</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/deploying-ml-model-on-kubernetes-nuclio">Deploying Ml Model On Kubernetes Nuclio</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/kubeflow-visualization-2">Kubeflow Visualization 2</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/linux-disk-free">Linux Disk Free</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/welcome-to-docker">Welcome To Docker</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/welcome-to-kubeflow">Welcome To Kubeflow</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/minio">Minio</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/k8s-tip-nodeselector">K8S Tip Nodeselector</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/information-theory">Information Theory</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/kubeflow-visualization-1">Kubeflow Visualization 1</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/nuclio">Nuclio 개념과 아키텍처</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/kubernetes-usage">자주쓰는 쿠버네티스 명령어</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/blog-essay">나에게 필요한 연재에 대해</a></li><li class="sidebarItem_spIe"><a aria-current="page" class="sidebarItemLink_eqrF sidebarItemLinkActive_XZSJ" href="/posts/alphapose">Alphapose 논문 리뷰와 사용</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/update-blog">지킬 블로그 업데이트</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/install-tar.gz">타르(tar) 파일 설치하기</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/install-kubeflow">쿠브플로우를 설치하는 다양한 방법</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/virtualbox-with-no-gui">GUI 없이 버추얼박스 사용하기</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/install-docker">나에게 필요한 도커 설치하기</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/install-kubernetes">나에게 필요한 쿠버네티스 설치하기</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/welcome-to-kubernetes">쿠버네티스 기본 개념과 필요성</a></li><li class="sidebarItem_spIe"><a class="sidebarItemLink_eqrF" href="/posts/first-post">First Post with Jekyll</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="blogPostTitle_uMeh" itemprop="headline">Alphapose 논문 리뷰와 사용</h1><div class="blogPostData_Vfxe margin-vert--md"><time datetime="2021-05-24T00:00:00.000Z" itemprop="datePublished">May 24, 2021</time> · <!-- -->9 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><a href="https://github.com/jwher" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://github.com/jwher.png" alt="Jeongwon Her"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/jwher" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jeongwon Her</span></a></div><small class="avatar__subtitle" itemprop="description">MLOps Engineer</small></div></div></div></div></header><div id="post-content" class="markdown" itemprop="articleBody"><p><img loading="lazy" alt="alphapose-logo" src="/assets/images/alphapose-logo-51aa3bc8632dee0ded1f95a8b9bd51d5.jpg" width="832" height="563" class="img_E7b_"><br>
<em>Regional Multi-Person pose Estimation</em>  </p><h2 class="anchor anchorWithStickyNavbar_mojV" id="computer-vision">Computer Vision<a class="hash-link" href="#computer-vision" title="Direct link to heading">​</a></h2><p>컴퓨터 비전은 기계의 시각적인 부분을 연구합니다. 범위를 좁혀 보면, 사람의 시각을 사용해야 하는 일을
컴퓨터가 수행할 수 있도록 만드는 것을 목표로 하고 있습니다.  </p><p>한국에서 인공지능이 대중적인 관심을 끌게 된 것은 단연 <a href="https://ko.wikipedia.org/wiki/%EC%95%8C%ED%8C%8C%EA%B3%A0" target="_blank" rel="noopener noreferrer">Alpha GO</a>
이후겠지만, 학자들이 다시 인공지능(신경망)에 관심을 갖게 된 것은 컴퓨터 비전의 <a href="https://en.wikipedia.org/wiki/AlexNet" target="_blank" rel="noopener noreferrer">AlexNet</a>입니다.  </p><p><img loading="lazy" alt="alexnet" src="/assets/images/alexnet-2cae39c7c6aae763b6e1c1ded716b119.jpg" width="248" height="203" class="img_E7b_"><br>
<em>AlexNet 신경망에 대해 공부할때 한번씩 봤을 이미지</em>  </p><p>컴퓨터 비전은 다시 하위에 많은 영역이 있습니다. 예를 들어 Alex Net은 Object Detection에 해당합니다.
여기에서 다루는 Alphapose는 Pose Estimation을 위한 Keypoint Detection에 해당합니다.
(Pose를 &#x27;자세&#x27;로 번역할 수 있겠지만, 용어의 혼동을 피해 &#x27;포즈&#x27;라고 부르겠습니다)</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="체험해보자">체험해보자<a class="hash-link" href="#체험해보자" title="Direct link to heading">​</a></h3><p>컴퓨터 비전을 처음 접하는 사람이라면 감이 잘 안잡힐 수 있습니다.<br>
<!-- -->구글 <a href="https://experiments.withgoogle.com/collection/ai/move-mirror/view" target="_blank" rel="noopener noreferrer">Move Mirror</a> 링크를 통해 Pose Estimation이 뭔지 브라우저에서 체험해 볼 수 있습니다.
<a href="https://experiments.withgoogle.com/collection/ai/move-mirror/view" target="_blank" rel="noopener noreferrer">Move Mirror</a>는 webcam으로 들어온 사진을 <a href="https://github.com/tensorflow/tfjs" target="_blank" rel="noopener noreferrer">Javascript library</a>로 포즈를 인식하고,
가장 유사한 사진을 보여줍니다. </p><br><h2 class="anchor anchorWithStickyNavbar_mojV" id="alphapose">Alphapose<a class="hash-link" href="#alphapose" title="Direct link to heading">​</a></h2><p><em>왜 Alphapose인데?</em></p><p><img loading="lazy" alt="alphapose_17" src="/assets/images/alphapose_17-887138a3b554288e634662685cb177c9.gif" width="320" height="180" class="img_E7b_"></p><p>딥러닝 모델에서 <em>속도</em>와 <em>정확도</em>는 Trade Off 관계입니다. 모델이 커지고 레이어가 많아질수록 정확해지지만, 속도는 느려지죠. 하지만 대부분 출판되는 논문은 <em>정확도</em>에 초점을 두고 있습니다.
하지만, 현실에서 등장하는 vision 문제는, 동영상과 실시간 스트리밍을 처리해야 되고 <em>속도</em> 에 중점을 준 모델이 필요합니다.</p><p><a href="https://openaccess.thecvf.com/CVPR2017" target="_blank" rel="noopener noreferrer">CVPR 2017</a> Carnegie Mellon University에서 <a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose" target="_blank" rel="noopener noreferrer">OpenPose</a>를 발표했습니다.
<a href="https://github.com/MVIG-SJTU/AlphaPose" target="_blank" rel="noopener noreferrer">Alphapose</a>는 조금 뒤인 <a href="https://openaccess.thecvf.com/ICCV2017" target="_blank" rel="noopener noreferrer">ICCV 2017</a>에 나왔고, OpenPose보다 뛰어난 성능을 보여줍니다. Alphapose는 pytorch 기반으로 작성되었습니다.
마침 업무에서도 pytorch 기반 모델로 통일하기로 했고, 상업용 라이선스도 alphapose가 더 싸 선택하게 되었습니다.</p><p>둘 다 현재(2021) 기준으로 굉장히 오래되었으나, Alphapose는 <a href="http://human-pose.mpi-inf.mpg.de/" target="_blank" rel="noopener noreferrer">MPII</a> 데이터 셋에서 아직도 1위를 기록하고 있습니다. <a href="https://cocodataset.org/#home" target="_blank" rel="noopener noreferrer">COCO</a> 데이터 셋 에서도 pytorch 기반 모델 중에 2번째로 뛰어난 순위를 기록하고 있습니다.<br>
<!-- -->(사용해 보진 않았으나 2019년에는 MXNet 버전도 나왔습니다)  </p><br><h3 class="anchor anchorWithStickyNavbar_mojV" id="왜-빠른데">왜 빠른데?<a class="hash-link" href="#왜-빠른데" title="Direct link to heading">​</a></h3><p>Alphapose는 backbone으로 <a href="https://pjreddie.com/media/files/papers/YOLOv3.pdf" target="_blank" rel="noopener noreferrer">YOLOv3</a>을 사용합니다(github master branch 기준).<br>
<img loading="lazy" alt="alphapose-yolo" src="/assets/images/alphapose-yolo-c4e819ba87490a1aeee13722c16d828e.png" width="1006" height="625" class="img_E7b_">
<em>0.5 IOU에서 속도/정확도 tradeoff</em></p><p>논문에서는 ResNet backbone인 RetinaNet 보다 3배 빠른 <em>속도</em>를 보였다고 소개합니다.
<em>정확도</em>에서도 RetinaNet보다 오히려 조금 나음을 보여주고 있습니다.
현재(21.05) 최신 모델인 HRNet과 성능을 비교해 보지 못해 가장 좋은지는 모르겠습니다만, 상당히 빠르고 정확함을 알 수 있습니다.
(YOLO의 backbone인 Darknet은 다른 포스트에서 다루겠습니다)</p><br><h3 class="anchor anchorWithStickyNavbar_mojV" id="paper">Paper<a class="hash-link" href="#paper" title="Direct link to heading">​</a></h3><p><a href="https://openaccess.thecvf.com/content_iccv_2017/html/Fang_RMPE_Regional_Multi-Person_ICCV_2017_paper.html" target="_blank" rel="noopener noreferrer">원문</a></p><p>최신 Human detector의 등장으로 Regional Multi-Person pose Estimation의 성능은 향상되었으나,
localization과 recognition의 작은 오류는 피할 수 없습니다.
Alphapose는 two-step 모델(bounding box-&gt;pose estimation)로써 bounding box의 정확도가 품질을 좌우합니다.
따라서 이 논문은 부정확한 bbx(bounding box)를 줄이기 위해 세 항목을 제안합니다.</p><ul><li><a href="#sstn">SSTN</a>: Symmetric Spatial Transformer Network</li><li><a href="#nms">NMS</a>: Parametric Pose Non-Maximum Suppression</li><li><a href="#pgpg">PGPG</a>: Pose-Guided Proposals Generator</li></ul><p>이 방법으로 부정확하고 중첩된 bbox를 줄여 MPII 데이터 셋에서 76.7 mAP 성능을 기록했습니다.</p><p><img loading="lazy" alt="alphapose-architecture" src="/assets/images/alphapose-architecture-bc8c438c49e5927a849e5720fccdbe89.png" width="742" height="234" class="img_E7b_"><br>
<em>RMPE 프레임워크</em></p><br><h4 class="anchor anchorWithStickyNavbar_mojV" id="sstn">SSTN<a class="hash-link" href="#sstn" title="Direct link to heading">​</a></h4><p><img loading="lazy" alt="sstn" src="/assets/images/alphapose-fig4-1b30a540728df708f1232d2ae87f5a8f.png" width="602" height="239" class="img_E7b_"></p><p>STN(Spatial Transformer Network)이 좋은 사람 영역을 추출하도록, 학습 단계에서 Parallel SPPE(Single Person Pose Estimator)를 둡니다. 하지만 여기서 사용된 SPPE는 SDTN이 빠져있습니다.
학습할 때 parallel SPPE의 가중치(weight)를 고정하고 직접 참(truth) 포즈와 비교해 STN을 업데이트 합니다.
이때, 정확한 위치(center-located)에 있지 않으면 STN에 큰 오류가 전파되어 성능이 향상됩니다.</p><p>성능 향상치는 <a href="#ablation-studies">ablation studies의 a</a>에서 비교하고 있습니다. </p><br><h4 class="anchor anchorWithStickyNavbar_mojV" id="nms">NMS<a class="hash-link" href="#nms" title="Direct link to heading">​</a></h4><p>가장 정확한(confident) 포즈를 레퍼런스로 선택합니다.
그리고 너무 가까운 포즈는 elimination criterion(pose similarity)을 사용해 지웁니다.
이때 포즈 거리(pose distance)를 지표(metric)로 사용해 계산하게 됩니다.</p><p><img loading="lazy" alt="ksim" src="/assets/images/ksim-a2e9d58f617b446eba26ca2c05b30d8a.png" width="580" height="154" class="img_E7b_">
<img loading="lazy" alt="hsim" src="/assets/images/hsim-9d4efb7faf4a8e1458d37d173a800552.png" width="518" height="102" class="img_E7b_">
<img loading="lazy" alt="distance" src="/assets/images/distance-934b23dc6ef4a5ae60fceb650c86abe0.png" width="632" height="58" class="img_E7b_"></p><p>포즈i와 포즈j간 distance function은, 포즈간 몇개의 관절(joint)이 일치하는지 의마하는 soft matching function <strong>Ksim</strong>과, 부분간의 공간거리인 <strong>Hsim</strong>의 합으로 이루어집니다.
여기서 λ는 두 거리간 weight balancing 입니다.</p><p>성능 향상치는 <a href="#ablation-studies">ablation studies의 c</a>에서 비교하고 있습니다. </p><br><h4 class="anchor anchorWithStickyNavbar_mojV" id="pgpg">PGPG<a class="hash-link" href="#pgpg" title="Direct link to heading">​</a></h4><p>two-stage 모델에서 데이터 augmentation은 SSTN+SSPE가 불완전한 사람의 의도에 적응하게 만들어야 합니다.
정답(ground truth) bbx와 감지된(detected) bbx의 offset은 포즈마다 다릅니다. 이 분포를 모델링 할 수 있으면 사람이 만든(generated by the human detector) 것과 비슷한 샘플을 많이 얻을 수 있습니다.</p><p>성능 향상치는 <a href="#ablation-studies">ablation studies의 b</a>에서 비교합니다.</p><br><h4 class="anchor anchorWithStickyNavbar_mojV" id="ablation-studies">Ablation Studies<a class="hash-link" href="#ablation-studies" title="Direct link to heading">​</a></h4><p><img loading="lazy" alt="ablation" src="/assets/images/alphapose-ablation-4c669e36905bb29a9a54078fe08717c9.png" width="1012" height="337" class="img_E7b_"><br>
<em>w/o는 without(x)의 의미입니다</em></p><br><h4 class="anchor anchorWithStickyNavbar_mojV" id="failure-cases">Failure cases<a class="hash-link" href="#failure-cases" title="Direct link to heading">​</a></h4><p><img loading="lazy" alt="failure" src="/assets/images/alphapose-failure-dad4dd5a970474d923e56c4813d2c7c3.png" width="602" height="86" class="img_E7b_">  </p><ol><li>SPPE는 희소하게 발생하는 특이한 자세에서 실패합니다</li><li>너무 겹치는 사람을 구분하지 못합니다</li><li>사람 인식(detect)을 실패하면 찾을 수 없습니다</li><li>반대로 사람과 비슷한 사물을 오인식 할 수 있습니다</li></ol><br><p>리뷰를 하고 보니 안타깝게도 paper에는 속도 관련 이야기가 없었습니다.
정확도는 높아졌으나, SPPE를 부착했을 때 어느정도 속도가 나오는지 정량적으로 측정해 보고 싶습니다.
기회가 되면 속도를 측정해 비교해 보고 싶습니다. </p><br><h2 class="anchor anchorWithStickyNavbar_mojV" id="사용하기">사용하기<a class="hash-link" href="#사용하기" title="Direct link to heading">​</a></h2><p><img loading="lazy" alt="alphapose" src="/assets/images/alphapose-error-07ccf41a4267d1fda42d9559b3aa1929.gif" width="1280" height="720" class="img_E7b_"></p><ul><li>cuda 11.0</li><li>cudnn 8.0</li><li>pytorch 1.7.0</li></ul><p>도커 이미지로 빌드하여 docker hub에 등록하였습니다. 간단하게 pull 해서 사용할 수 있습니다.</p><div class="language-bash codeBlockContainer_MPoW theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_B9tL"><pre tabindex="0" class="prism-code language-bash codeBlock__0OG thin-scrollbar"><code class="codeBlockLines_gEuF"><span class="token-line" style="color:#393A34"><span class="token plain">$ </span><span class="token function" style="color:#d73a49">docker</span><span class="token plain"> pull jwher/alphapose:v1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ conda activate alphapose</span><br></span></code></pre><div class="buttonGroup_hRr1"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_W9eQ" aria-hidden="true"><svg class="copyButtonIcon_XEyF" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_i9w9" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>자세한 demo inference 코드는 나중에 작성하겠습니다...</p><br><h2 class="anchor anchorWithStickyNavbar_mojV" id="reference">Reference<a class="hash-link" href="#reference" title="Direct link to heading">​</a></h2><p><a href="https://openaccess.thecvf.com/menu" target="_blank" rel="noopener noreferrer">Computer Vision Foundation</a><br>
<a href="https://paperswithcode.com/area/computer-vision" target="_blank" rel="noopener noreferrer">Paper with codes</a><br>
<a href="https://ko.wikipedia.org/wiki/%EC%BB%B4%ED%93%A8%ED%84%B0_%EB%B9%84%EC%A0%84" target="_blank" rel="noopener noreferrer">[위키]컴퓨터_비전</a></p></div><a href="https://www.buymeacoffee.com/jwher"><img style="margin:20px 0" src="https://img.buymeacoffee.com/button-api/?text=Buy me a coffee&amp;emoji=&amp;slug=jwher&amp;button_colour=40DCA5&amp;font_colour=ffffff&amp;font_family=Cookie&amp;outline_colour=000000&amp;coffee_colour=FFDD00"></a><footer class="row docusaurus-mt-lg blogPostDetailsFull_enUA"><div class="col"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/posts/tags/paper">paper</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/posts/tags/ml">ml</a></li></ul></div><div class="col margin-top--sm"><a href="https://github.com/jwher/jwher.github.io/posts/2021-05-24-alphapose/index.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_dcUD" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></footer><div></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/posts/blog-essay"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">나에게 필요한 연재에 대해</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/posts/update-blog"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">지킬 블로그 업데이트</div></a></nav></main><div class="col col--2"><div class="tableOfContents_cNA8 thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#computer-vision" class="table-of-contents__link toc-highlight">Computer Vision</a><ul><li><a href="#체험해보자" class="table-of-contents__link toc-highlight">체험해보자</a></li></ul></li><li><a href="#alphapose" class="table-of-contents__link toc-highlight">Alphapose</a><ul><li><a href="#왜-빠른데" class="table-of-contents__link toc-highlight">왜 빠른데?</a></li><li><a href="#paper" class="table-of-contents__link toc-highlight">Paper</a></li></ul></li><li><a href="#사용하기" class="table-of-contents__link toc-highlight">사용하기</a></li><li><a href="#reference" class="table-of-contents__link toc-highlight">Reference</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">
        <div class="copyright">
          Copyright © 2023, made by JWHer.<span class="heart-icon"></span>
        </div>
        </div></div></div></footer></div>
<script src="/assets/js/runtime~main.0c1c803e.js"></script>
<script src="/assets/js/main.9d471611.js"></script>
</body>
</html>